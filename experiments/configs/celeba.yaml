trials: 3
results_dir: results/celeba_complete/

shared_params:
  results_dir: "results/celeba/"
  trials: 3
  model_selection_trials: 1
  dataset_config:
    dataset: "celeba"
    image_size: 64
    num_classes: 1000
    batch_size: 512
    root_dir: "cem/data/CelebA" # REPLACE ME
    use_imbalance: true
    use_binary_vector_class: true
    num_concepts: 8
    label_binary_width: 1
    label_dataset_subsample: 12
    num_hidden_concepts: 0
    selected_concepts: false
    num_workers: 8
  intervention_config:
    competence_levels: [1]
    intervention_freq: 1
    intervention_batch_size: 256
    val_intervention_policies:
      - policy: "random"
        group_level: true
        use_prior: false
    intervention_policies:
      - policy: "random"
        group_level: true
        use_prior: false
      # Remove the following if you are only interested in random interventions
      - policy: "random"
        group_level: true
        use_prior: true
        include_run_names: [".*(CEM).*"]
#      - policy: "coop"
#        group_level: true
#        use_prior: False
#      - policy: "behavioural_cloning"
#        group_level: true
#        use_prior: False
#      - policy: "optimal_greedy"
#        group_level: true
#        use_prior: False
#      - policy: "global_val_error"
#        group_level: true
#        use_prior: False
#      - policy: "global_val_improvement"
#        group_level: true
#        use_prior: False
      ##########################################################################
  eval_config:
    additional_metrics:
      - name: "mixcem_sel"
        include_list: [".*(MixCEM).*", ".*(MixIntCEM).*"]
    additional_test_sets:
      - name: "OOD_sap_0.1"
        update_previous: true
        dataset_config:
          test_transformation_config:
            post_generation: true
            name: "salt_and_pepper"
            amount: 0.1
            s_vs_p: 0.5

  skip_repr_evaluation: true
  save_model: true
  max_epochs: 150
  lr_scheduler_patience: 10
  patience: 5
  emb_size: 16
  extra_dims: 0
  concept_loss_weight: [1, 10]
  learning_rate: 0.005
  weight_decay: 4.0e-06
  weight_loss: false
  c_extractor_arch: "resnet34"
  optimizer: "sgd"
  bool: false
  early_stopping_monitor: "val_loss"
  early_stopping_mode: "min"
  early_stopping_delta: 0.0
  momentum: 0.9
  sigmoidal_prob: false
  training_intervention_prob: 0.25
runs:

  - architecture: "ConceptEmbeddingModel"
    run_name: "CEM"
    emb_size: 32
    concept_loss_weight: 10
    sigmoidal_prob: true
    embedding_activation: "leakyrelu"


  - architecture: "ConceptBottleneckModel"
    run_name: "Hybrid-CBM"
    extra_dims: 200
    concept_loss_weight: 10
    sigmoidal_prob: true
    training_intervention_prob: 0
    embedding_activation: "leakyrelu"


  - architecture: "MixCEM"
    run_name: "MixCEM"
    concept_loss_weight: 10
    load_path_name: "MixCEM_r_1_g_ood_0.9_cwl_10_ce_0"
    all_intervened_loss_weight: 1
    ood_dropout_prob: 0.9
    calibration_epochs: 0
